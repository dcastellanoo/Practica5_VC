{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 7 - Entrenando un detector\n",
    "\n",
    "### Contenidos\n",
    "\n",
    "[Anotación de imágenes](#anotación-de-imágenes)  \n",
    "[Entrenamiento](#entrenamiento)\n",
    "[Resultados](#resultados)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción \n",
    "\n",
    "En esta práctica se propone el entrenamiento del YOLOv7 con el fin de detectar objetos de interés del estudiante. En nuestro caso, aprovechando el motivo de la celabración del mundial de Qatar 2022, hemos propuesto un detector capaz de distinguir los suguientes elementos propios de un partido de fútbol:\n",
    "\n",
    "- Football (balón de fútbol) - 0\n",
    "- Player (jugador) - 1\n",
    "- Referee (arbitro) -2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotación de imágenes\n",
    "\n",
    "Para el entrenamiento personalizado del detector es necesario las imágenes donde aparecen los objetos de interés y las etiquetas de estos, que se tratarán de archivos con formato \".txt\" con el mismo nombre que la archivo de la imagen a la que referencian. En estos últimos se especifican las coordenadas de los recuadros en los que están contenidos los objetos a detectar así como la clase del objeto.\n",
    "\n",
    "En nuestro caso, se ha accedido a un conjunto de datos en el servicio en la nube [Roboflow](https://roboflow.com). En concreto, se ha utilizado el dataset del proyecto subido en Roboflow llamado \"[futbol players Computer Vision Project](https://universe.roboflow.com/roboflow-100/soccer-players-5fuqs)\". Al descargar el conjunto de imágenes, estas vienen divididas en tres carpetas las cuales, cada una de ellas contiene una carpeta con las imágenes y otra con los etiquetados. Estas tres carpetas se corresponden a imágenes de entrenamiento (con las que se entrenan los modelos), de validación (con las que se selecciona el mejor de los modelos entrenados) y de test (error real cometido con un modelo seleccionado). \n",
    "Partiendo del anterior dataset, se ha creado un workspace en Roboflow al que se han subido las imágenes con el objetivo de escalarlas a un tamaño de 398x224 y añadir más imágenes de entrenamiento a nuestro conjunto de datos. En nuestro caso, se ha jugado con el brillo y la saturación de las imágenes existentes.\n",
    "\n",
    "<p align=center>\n",
    "    <img src=./resumen_dataset.png width=900>\n",
    "</p>\n",
    "\n",
    "\n",
    "En la anterior imágen sacada del workspace creado anteriormente muestra un resumen del conjunto de datos que se utilizará para el entrenamiento del detector \"yolov7\". Podrá acceder al workspace donde se encuentran las imágenes del dataset por el siguiente [enlace](https://universe.roboflow.com/test-tatu8/football-detector), habiendo usado la versión 2 para el entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Para el entrenamiento de detector, ejecutaremos el Anaconda Prompt y se activará el environment yolov7 creado en anteriores prácticas. Una vez activado, nos situaremos en la carpeta de yolov7 dentro del proyecto e incluiremos el archivo \"data.yaml\", que contiene la ruta relativa de los directorios con las imágenes y las clases a detectar y el cual ha sido generado por Roboflow, dentro de \"./yolov7/data\". Tras esto, se modificará el archivo \"./yolov7/cfg/training/yolov7.yaml\", el cual contiene la configuración de entrenamiento del yolov7, poniendo la variable \"nc\" a 3, pues se tienen 3 clases. Teniendo configurado lo anterior, se pasará a ejecutar el siguiente comando, el cual ejecuta el entrenamiento del \"yolov7\":\n",
    "\n",
    "```\n",
    "python train.py --workers 1 --device 0 --batch-size 8 --data data/data.yaml --img 398 224 --cfg cfg/training/yolov7.yaml --weights 'yolov7.pt' --name soccer --hyp data/hyp.scratch.custom.yaml --epochs 300\n",
    "```\n",
    "En el anterior comando se especifica que el entrenamiento constará con 300 épocas (--epochs 300) y con un batch-size de 8 (--batch-size 8). Para el entrenamiento, se ha utilizado un targeta gráfica NVIDIA RTX 2070 Super, para lo que se ha instalado CUDA previamente. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Una vez finalizado el entrenamiento, en la carpeta \"./yolov7/runs/train/soccer\" tendremos, por una parte una carpeta llamada \"weights\" con los pesos utilizados en diversas épocas destacando \"best.pt\", que contiene los pesos de la época de mejor resultado; y por otra parte, resúmenes y resultados del entrenamiento donde destaca la matriz de confusión:\n",
    "\n",
    "<p align=center>\n",
    "    <img src=./soccer/confusion_matrix.png width=900>\n",
    "</p>\n",
    "\n",
    "Se ha probado el detector con 3 imágenes distintas y con un vídeo, utilizando los pesos de \"./yolov7/runs/train/soccer/weights/best.pt\". Las detecciones se pueden encontrar en \"./yolov7/runs/detect\".\n",
    "\n",
    "Imágenes:\n",
    "\n",
    "```\n",
    "python detect.py --weights runs/train/soccer/weights/best.pt --source ../images_to_detect --conf 0.6\n",
    "```\n",
    "\n",
    "<p align=center>\n",
    "<img src=./images_detected/gol_cr7.png width=900>\n",
    "\n",
    "<img src=./images_detected/gol_lewan.png width=900>\n",
    "\n",
    "<img src=./images_detected/pedri.png width=900>\n",
    "</p>\n",
    "\n",
    "\n",
    "Vídeo:\n",
    "\n",
    "```\n",
    "python detect.py --weights runs/train/soccer/weights/best.pt --source ../gol_haaland_to_detect.mp4 --conf 0.6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('./gol_haaland_detection.mp4')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "\tprint(\"Error opening video file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "\t\n",
    "# Capture frame-by-frame\n",
    "\tret, frame = cap.read()\n",
    "\tif ret == True:\n",
    "\t# Display the resulting frame\n",
    "\t\tcv2.imshow('Frame', frame)\n",
    "\t\t\n",
    "\t# Press Q on keyboard to exit\n",
    "\t\tif cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "\t\t\tbreak\n",
    "\n",
    "# Break the loop\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "# When everything done, release\n",
    "# the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a744e02f709ae1d269b2f99ce3b80e3ec703b067208609a22bdd7c2622c08b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
